{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image_dir = \"techosmotr/train/fictivniye(fictitious)/\"\n",
    "real_image_dir = \"techosmotr/train/pravilniye(correct)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_paths_and_preprocess(directory, label):\n",
    "    image_paths = []\n",
    "    images = []\n",
    "    for subfolder in os.listdir(directory):\n",
    "        subfolder_path = os.path.join(directory, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for img in os.listdir(subfolder_path):\n",
    "                image_path = os.path.join(subfolder_path, img)\n",
    "                image = cv2.imread(image_path)  # Read the image\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, (224, 224))\n",
    "                    image = image / 255.0  # Normalize pixel values\n",
    "                    images.append(image)\n",
    "                    image_paths.append((image, label))\n",
    "    return images, image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images, fake_image_paths = collect_image_paths_and_preprocess(fake_image_dir, 1)\n",
    "real_images, real_image_paths = collect_image_paths_and_preprocess(real_image_dir, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'image': [img[0] for img in fake_image_paths + real_image_paths],\n",
    "                     'label': [img[1] for img in fake_image_paths + real_image_paths]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    # Binary classification, so using sigmoid activation\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array([img for img in train_data['image']])\n",
    "train_labels = np.array(train_data['label'])\n",
    "valid_images = np.array([img for img in valid_data['image']])\n",
    "valid_labels = np.array(valid_data['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "83/83 [==============================] - 59s 660ms/step - loss: 0.3101 - accuracy: 0.8774 - val_loss: 0.1701 - val_accuracy: 0.9339\n",
      "Epoch 2/7\n",
      "83/83 [==============================] - 50s 602ms/step - loss: 0.1192 - accuracy: 0.9499 - val_loss: 0.1328 - val_accuracy: 0.9484\n",
      "Epoch 3/7\n",
      "83/83 [==============================] - 48s 584ms/step - loss: 0.0652 - accuracy: 0.9744 - val_loss: 0.1835 - val_accuracy: 0.9377\n",
      "Epoch 4/7\n",
      "83/83 [==============================] - 49s 587ms/step - loss: 0.0436 - accuracy: 0.9842 - val_loss: 0.1811 - val_accuracy: 0.9423\n",
      "Epoch 5/7\n",
      "83/83 [==============================] - 49s 588ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.2262 - val_accuracy: 0.9415\n",
      "Epoch 6/7\n",
      "83/83 [==============================] - 49s 588ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.2465 - val_accuracy: 0.9377\n",
      "Epoch 7/7\n",
      "83/83 [==============================] - 49s 588ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.2853 - val_accuracy: 0.9438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183ea896c50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, validation_data=(\n",
    "    valid_images, valid_labels), epochs=7, batch_size=64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 5s 110ms/step\n",
      "F1 Score: 0.9114832535885168\n"
     ]
    }
   ],
   "source": [
    "valid_predictions = model.predict(valid_images)\n",
    "valid_predictions = (valid_predictions > 0.5).astype(int)  # Convert to binary predictions\n",
    "\n",
    "f1 = f1_score(valid_labels, valid_predictions)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 101ms/step\n",
      "Prediction completed and results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "def preprocess_test_images(image_paths):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            image = image / 255.0\n",
    "            images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "# Define the path to test images\n",
    "test_data_dir = \"techosmotr/test_data\"\n",
    "test_image_paths = [os.path.join(test_data_dir, img)\n",
    "                    for img in os.listdir(test_data_dir)]\n",
    "\n",
    "# Preprocess the test images\n",
    "test_images = preprocess_test_images(test_image_paths)\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = model.predict(test_images)\n",
    "test_predictions = (test_predictions > 0.5).astype(\n",
    "    int)  # Convert to binary predictions\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results = pd.DataFrame({'file_index': [os.path.basename(img).split(\n",
    "    '.')[0] for img in test_image_paths], 'class': test_predictions[:, 0]})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('results.csv', index=False)\n",
    "\n",
    "print(\"Prediction completed and results saved to results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
